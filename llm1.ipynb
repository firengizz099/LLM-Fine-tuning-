{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1zS1yj63ebP"
      },
      "source": [
        "## Compare finetuned vs. non-finetuned models\n",
        "\n",
        "Bu kod, farklı modelleri kullanarak metin girdilerine cevaplar almayı amaçlayan bir dizi işlemi gerçekleştiriyor. İlk önce temel bir model kullanılıyor, ardından bu model biraz daha özel bir konuya odaklanan bir modelle değiştiriliyor. Son olarak, \"chat-gpt\" modeli kullanılarak başka bir metin girdisi için cevap alınıyor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "JjqEDXsx3Z9y",
        "outputId": "c9060dcc-2d48-4003-e84b-e6a473888c92"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-36d726b8a797>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllama\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasicModelRunner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#İlk olarak, \"llama\" kütüphanesinden \"BasicModelRunner\" sınıfını içe aktarıyoruz:\n",
        "from llama import BasicModelRunner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqmScHvj3kf2"
      },
      "source": [
        "### Try Non-Finetuned models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsetcHLw3Z6b"
      },
      "outputs": [],
      "source": [
        "#Ardından, \"meta-llama/Llama-2-7b-hf\" isimli bir modeli kullanarak BasicModelRunner sınıfından bir nesne oluşturuyoruz \n",
        "#ve bunu \"non_finetuned\" adlı değişkene atıyoruz:\n",
        "\n",
        "non_finetuned = BasicModelRunner(\"meta-llama/Llama-2-7b-hf\")\n",
        "#Bu modeli kullanarak bir metin girdisi (\"Tell me how to train my dog to sit\") ile çağrı yapıyoruz ve çıktıyı \n",
        "# \"non_finetuned_output\" adlı değişkene atıyoru\n",
        "non_finetuned_output = non_finetuned(\"Tell me how to train my dog to sit\")\n",
        "print(non_finetuned_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ArDPjAa3Z07"
      },
      "outputs": [],
      "source": [
        "#Aynı işlemleri diğer metin girdileri için tekrarlıyoruz:\n",
        "\n",
        "print(non_finetuned(\"What do you think of Mars?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkR_IJPE3Zq2"
      },
      "outputs": [],
      "source": [
        "print(non_finetuned(\"taylor swift's best friend\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGg23fKO31Ot"
      },
      "outputs": [],
      "source": [
        "print(non_finetuned(\"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
        "Customer: I didn't get my item\n",
        "Agent: I'm sorry to hear that. Which item was it?\n",
        "Customer: the blanket\n",
        "Agent:\"\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mM2XcCX34Pg"
      },
      "source": [
        "## Compare to finetuned models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4KPqGvh37OP"
      },
      "outputs": [],
      "source": [
        "#Ardından, başka bir modeli (\"meta-llama/Llama-2-7b-chat-hf\") kullanarak aynı işlemleri gerçekleştiriyoruz:\n",
        "\n",
        "finetuned_model = BasicModelRunner(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "finetuned_output = finetuned_model(\"Tell me how to train my dog to sit\")\n",
        "print(finetuned_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8gwCoZ937En"
      },
      "outputs": [],
      "source": [
        "print(finetuned_model(\"[INST]Tell me how to train my dog to sit[/INST]\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BNwnmRx4FgK"
      },
      "outputs": [],
      "source": [
        "print(non_finetuned(\"[INST]Tell me how to train my dog to sit[/INST]\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnizkZlX4Fc5"
      },
      "outputs": [],
      "source": [
        "print(finetuned_model(\"What do you think of Mars?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJYZGqap4PRi"
      },
      "outputs": [],
      "source": [
        "print(finetuned_model(\"taylor swift's best friend\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1q3gG_dL4SW5"
      },
      "outputs": [],
      "source": [
        "print(finetuned_model(\"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
        "Customer: I didn't get my item\n",
        "Agent: I'm sorry to hear that. Which item was it?\n",
        "Customer: the blanket\n",
        "Agent:\"\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR66rxj34YFN"
      },
      "source": [
        "## Compare to ChatGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16VpqnBE4XJf"
      },
      "outputs": [],
      "source": [
        "#Son olarak, \"chat-gpt\" modelini kullanarak bir metin girdisi ile çağrı yapıyoruz:\n",
        "\n",
        "\n",
        "chatgpt = BasicModelRunner(\"chat-gpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2T31mtF4eeB"
      },
      "outputs": [],
      "source": [
        "print(chatgpt(\"Tell me how to train my dog to sit\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
